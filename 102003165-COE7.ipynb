{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DrcmPM3sTD7g"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "L5MwGHdoTwBt"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('Creditcard_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "l5qTuHOkT5Kb",
        "outputId": "b6c6f3aa-64e9-4422-cd88-7b4959a8335c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.425966</td>\n",
              "      <td>0.960523</td>\n",
              "      <td>1.141109</td>\n",
              "      <td>-0.168252</td>\n",
              "      <td>0.420987</td>\n",
              "      <td>-0.029728</td>\n",
              "      <td>0.476201</td>\n",
              "      <td>0.260314</td>\n",
              "      <td>-0.568671</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.208254</td>\n",
              "      <td>-0.559825</td>\n",
              "      <td>-0.026398</td>\n",
              "      <td>-0.371427</td>\n",
              "      <td>-0.232794</td>\n",
              "      <td>0.105915</td>\n",
              "      <td>0.253844</td>\n",
              "      <td>0.081080</td>\n",
              "      <td>3.67</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4</td>\n",
              "      <td>1.229658</td>\n",
              "      <td>0.141004</td>\n",
              "      <td>0.045371</td>\n",
              "      <td>1.202613</td>\n",
              "      <td>0.191881</td>\n",
              "      <td>0.272708</td>\n",
              "      <td>-0.005159</td>\n",
              "      <td>0.081213</td>\n",
              "      <td>0.464960</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.167716</td>\n",
              "      <td>-0.270710</td>\n",
              "      <td>-0.154104</td>\n",
              "      <td>-0.780055</td>\n",
              "      <td>0.750137</td>\n",
              "      <td>-0.257237</td>\n",
              "      <td>0.034507</td>\n",
              "      <td>0.005168</td>\n",
              "      <td>4.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>-0.644269</td>\n",
              "      <td>1.417964</td>\n",
              "      <td>1.074380</td>\n",
              "      <td>-0.492199</td>\n",
              "      <td>0.948934</td>\n",
              "      <td>0.428118</td>\n",
              "      <td>1.120631</td>\n",
              "      <td>-3.807864</td>\n",
              "      <td>0.615375</td>\n",
              "      <td>...</td>\n",
              "      <td>1.943465</td>\n",
              "      <td>-1.015455</td>\n",
              "      <td>0.057504</td>\n",
              "      <td>-0.649709</td>\n",
              "      <td>-0.415267</td>\n",
              "      <td>-0.051634</td>\n",
              "      <td>-1.206921</td>\n",
              "      <td>-1.085339</td>\n",
              "      <td>40.80</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7</td>\n",
              "      <td>-0.894286</td>\n",
              "      <td>0.286157</td>\n",
              "      <td>-0.113192</td>\n",
              "      <td>-0.271526</td>\n",
              "      <td>2.669599</td>\n",
              "      <td>3.721818</td>\n",
              "      <td>0.370145</td>\n",
              "      <td>0.851084</td>\n",
              "      <td>-0.392048</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.073425</td>\n",
              "      <td>-0.268092</td>\n",
              "      <td>-0.204233</td>\n",
              "      <td>1.011592</td>\n",
              "      <td>0.373205</td>\n",
              "      <td>-0.384157</td>\n",
              "      <td>0.011747</td>\n",
              "      <td>0.142404</td>\n",
              "      <td>93.20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>-0.338262</td>\n",
              "      <td>1.119593</td>\n",
              "      <td>1.044367</td>\n",
              "      <td>-0.222187</td>\n",
              "      <td>0.499361</td>\n",
              "      <td>-0.246761</td>\n",
              "      <td>0.651583</td>\n",
              "      <td>0.069539</td>\n",
              "      <td>-0.736727</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.246914</td>\n",
              "      <td>-0.633753</td>\n",
              "      <td>-0.120794</td>\n",
              "      <td>-0.385050</td>\n",
              "      <td>-0.069733</td>\n",
              "      <td>0.094199</td>\n",
              "      <td>0.246219</td>\n",
              "      <td>0.083076</td>\n",
              "      <td>3.68</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "5     2 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
              "6     4  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
              "7     7 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
              "8     7 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
              "9     9 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
              "\n",
              "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
              "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
              "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
              "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
              "5  0.260314 -0.568671  ... -0.208254 -0.559825 -0.026398 -0.371427 -0.232794   \n",
              "6  0.081213  0.464960  ... -0.167716 -0.270710 -0.154104 -0.780055  0.750137   \n",
              "7 -3.807864  0.615375  ...  1.943465 -1.015455  0.057504 -0.649709 -0.415267   \n",
              "8  0.851084 -0.392048  ... -0.073425 -0.268092 -0.204233  1.011592  0.373205   \n",
              "9  0.069539 -0.736727  ... -0.246914 -0.633753 -0.120794 -0.385050 -0.069733   \n",
              "\n",
              "        V26       V27       V28  Amount  Class  \n",
              "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1  0.125895 -0.008983  0.014724    2.69      1  \n",
              "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "3 -0.221929  0.062723  0.061458  123.50      0  \n",
              "4  0.502292  0.219422  0.215153   69.99      0  \n",
              "5  0.105915  0.253844  0.081080    3.67      0  \n",
              "6 -0.257237  0.034507  0.005168    4.99      0  \n",
              "7 -0.051634 -1.206921 -1.085339   40.80      0  \n",
              "8 -0.384157  0.011747  0.142404   93.20      0  \n",
              "9  0.094199  0.246219  0.083076    3.68      0  \n",
              "\n",
              "[10 rows x 31 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Qf_tApU4eoLb"
      },
      "outputs": [],
      "source": [
        "x_features=df.iloc[:, df.columns!= 'Class']\n",
        "y_feature=df.iloc[:,df.columns=='Class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Class\n",
              "0      0\n",
              "1      1\n",
              "2      0\n",
              "3      0\n",
              "4      0"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#x_features.head()\n",
        "y_feature.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using SMOTE : Synthetic Minority Over-sampling Technique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ErqbkjCwiivR"
      },
      "outputs": [],
      "source": [
        "#Using SMOTE\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "nCJ-lGk1ilfZ"
      },
      "outputs": [],
      "source": [
        "sample=SMOTE()\n",
        "x_features,y_feature=sample.fit_resample(x_features,y_feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "HZhd2O5GiudX",
        "outputId": "a090a5e3-d389-4bbe-a35a-39d20ed161ec"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.620000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.690000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.660000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.990000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1521</th>\n",
              "      <td>496</td>\n",
              "      <td>-1.805938</td>\n",
              "      <td>-2.327118</td>\n",
              "      <td>2.326886</td>\n",
              "      <td>1.097871</td>\n",
              "      <td>2.315570</td>\n",
              "      <td>0.553011</td>\n",
              "      <td>-1.986337</td>\n",
              "      <td>0.745473</td>\n",
              "      <td>0.884782</td>\n",
              "      <td>...</td>\n",
              "      <td>0.578833</td>\n",
              "      <td>0.382932</td>\n",
              "      <td>1.083578</td>\n",
              "      <td>0.285854</td>\n",
              "      <td>-0.825569</td>\n",
              "      <td>-0.195759</td>\n",
              "      <td>0.816201</td>\n",
              "      <td>-0.117572</td>\n",
              "      <td>-0.159734</td>\n",
              "      <td>1.572550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1522</th>\n",
              "      <td>193</td>\n",
              "      <td>0.344351</td>\n",
              "      <td>0.318939</td>\n",
              "      <td>0.795990</td>\n",
              "      <td>0.342021</td>\n",
              "      <td>0.422364</td>\n",
              "      <td>-0.409636</td>\n",
              "      <td>0.304112</td>\n",
              "      <td>-0.011521</td>\n",
              "      <td>-0.210127</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.088752</td>\n",
              "      <td>-0.108989</td>\n",
              "      <td>-0.270857</td>\n",
              "      <td>-0.042334</td>\n",
              "      <td>-0.049916</td>\n",
              "      <td>0.256699</td>\n",
              "      <td>-0.105876</td>\n",
              "      <td>-0.047148</td>\n",
              "      <td>-0.041440</td>\n",
              "      <td>2.014376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1523</th>\n",
              "      <td>283</td>\n",
              "      <td>-1.258657</td>\n",
              "      <td>1.445112</td>\n",
              "      <td>-1.075763</td>\n",
              "      <td>2.930605</td>\n",
              "      <td>-0.347137</td>\n",
              "      <td>-1.022391</td>\n",
              "      <td>-1.798167</td>\n",
              "      <td>0.998816</td>\n",
              "      <td>-2.014007</td>\n",
              "      <td>...</td>\n",
              "      <td>0.067981</td>\n",
              "      <td>0.293833</td>\n",
              "      <td>-0.216540</td>\n",
              "      <td>-0.294882</td>\n",
              "      <td>0.121743</td>\n",
              "      <td>0.081397</td>\n",
              "      <td>0.162221</td>\n",
              "      <td>0.179926</td>\n",
              "      <td>-0.095770</td>\n",
              "      <td>0.808800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1524</th>\n",
              "      <td>356</td>\n",
              "      <td>-1.696256</td>\n",
              "      <td>1.675411</td>\n",
              "      <td>-1.279630</td>\n",
              "      <td>3.427237</td>\n",
              "      <td>-0.496162</td>\n",
              "      <td>-1.365022</td>\n",
              "      <td>-2.084248</td>\n",
              "      <td>1.116322</td>\n",
              "      <td>-2.285682</td>\n",
              "      <td>...</td>\n",
              "      <td>0.091223</td>\n",
              "      <td>0.378256</td>\n",
              "      <td>-0.172784</td>\n",
              "      <td>-0.362762</td>\n",
              "      <td>0.323519</td>\n",
              "      <td>0.074121</td>\n",
              "      <td>0.163484</td>\n",
              "      <td>0.212018</td>\n",
              "      <td>-0.113201</td>\n",
              "      <td>0.464507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1525</th>\n",
              "      <td>420</td>\n",
              "      <td>-0.728593</td>\n",
              "      <td>0.428636</td>\n",
              "      <td>1.484341</td>\n",
              "      <td>0.169187</td>\n",
              "      <td>0.937816</td>\n",
              "      <td>-0.671453</td>\n",
              "      <td>0.762955</td>\n",
              "      <td>-0.097615</td>\n",
              "      <td>-0.138320</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.103472</td>\n",
              "      <td>0.027491</td>\n",
              "      <td>0.149260</td>\n",
              "      <td>-0.176506</td>\n",
              "      <td>0.036949</td>\n",
              "      <td>0.036538</td>\n",
              "      <td>-0.348434</td>\n",
              "      <td>-0.037484</td>\n",
              "      <td>-0.054870</td>\n",
              "      <td>0.998008</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1526 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Time        V1        V2        V3        V4        V5        V6  \\\n",
              "0        0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
              "1        0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
              "2        1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
              "3        1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
              "4        2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
              "...    ...       ...       ...       ...       ...       ...       ...   \n",
              "1521   496 -1.805938 -2.327118  2.326886  1.097871  2.315570  0.553011   \n",
              "1522   193  0.344351  0.318939  0.795990  0.342021  0.422364 -0.409636   \n",
              "1523   283 -1.258657  1.445112 -1.075763  2.930605 -0.347137 -1.022391   \n",
              "1524   356 -1.696256  1.675411 -1.279630  3.427237 -0.496162 -1.365022   \n",
              "1525   420 -0.728593  0.428636  1.484341  0.169187  0.937816 -0.671453   \n",
              "\n",
              "            V7        V8        V9  ...       V20       V21       V22  \\\n",
              "0     0.239599  0.098698  0.363787  ...  0.251412 -0.018307  0.277838   \n",
              "1    -0.078803  0.085102 -0.255425  ... -0.069083 -0.225775 -0.638672   \n",
              "2     0.791461  0.247676 -1.514654  ...  0.524980  0.247998  0.771679   \n",
              "3     0.237609  0.377436 -1.387024  ... -0.208038 -0.108300  0.005274   \n",
              "4     0.592941 -0.270533  0.817739  ...  0.408542 -0.009431  0.798278   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "1521 -1.986337  0.745473  0.884782  ...  0.578833  0.382932  1.083578   \n",
              "1522  0.304112 -0.011521 -0.210127  ... -0.088752 -0.108989 -0.270857   \n",
              "1523 -1.798167  0.998816 -2.014007  ...  0.067981  0.293833 -0.216540   \n",
              "1524 -2.084248  1.116322 -2.285682  ...  0.091223  0.378256 -0.172784   \n",
              "1525  0.762955 -0.097615 -0.138320  ... -0.103472  0.027491  0.149260   \n",
              "\n",
              "           V23       V24       V25       V26       V27       V28      Amount  \n",
              "0    -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.620000  \n",
              "1     0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.690000  \n",
              "2     0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.660000  \n",
              "3    -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.500000  \n",
              "4    -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.990000  \n",
              "...        ...       ...       ...       ...       ...       ...         ...  \n",
              "1521  0.285854 -0.825569 -0.195759  0.816201 -0.117572 -0.159734    1.572550  \n",
              "1522 -0.042334 -0.049916  0.256699 -0.105876 -0.047148 -0.041440    2.014376  \n",
              "1523 -0.294882  0.121743  0.081397  0.162221  0.179926 -0.095770    0.808800  \n",
              "1524 -0.362762  0.323519  0.074121  0.163484  0.212018 -0.113201    0.464507  \n",
              "1525 -0.176506  0.036949  0.036538 -0.348434 -0.037484 -0.054870    0.998008  \n",
              "\n",
              "[1526 rows x 30 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "huACzugmkJWx"
      },
      "outputs": [],
      "source": [
        "x_features['Class']=y_feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "aDZg3-DJkQF9",
        "outputId": "18481ea3-3883-4525-efdc-f09e39f29ad1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.620000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.690000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.660000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.500000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.990000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1521</th>\n",
              "      <td>496</td>\n",
              "      <td>-1.805938</td>\n",
              "      <td>-2.327118</td>\n",
              "      <td>2.326886</td>\n",
              "      <td>1.097871</td>\n",
              "      <td>2.315570</td>\n",
              "      <td>0.553011</td>\n",
              "      <td>-1.986337</td>\n",
              "      <td>0.745473</td>\n",
              "      <td>0.884782</td>\n",
              "      <td>...</td>\n",
              "      <td>0.382932</td>\n",
              "      <td>1.083578</td>\n",
              "      <td>0.285854</td>\n",
              "      <td>-0.825569</td>\n",
              "      <td>-0.195759</td>\n",
              "      <td>0.816201</td>\n",
              "      <td>-0.117572</td>\n",
              "      <td>-0.159734</td>\n",
              "      <td>1.572550</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1522</th>\n",
              "      <td>193</td>\n",
              "      <td>0.344351</td>\n",
              "      <td>0.318939</td>\n",
              "      <td>0.795990</td>\n",
              "      <td>0.342021</td>\n",
              "      <td>0.422364</td>\n",
              "      <td>-0.409636</td>\n",
              "      <td>0.304112</td>\n",
              "      <td>-0.011521</td>\n",
              "      <td>-0.210127</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108989</td>\n",
              "      <td>-0.270857</td>\n",
              "      <td>-0.042334</td>\n",
              "      <td>-0.049916</td>\n",
              "      <td>0.256699</td>\n",
              "      <td>-0.105876</td>\n",
              "      <td>-0.047148</td>\n",
              "      <td>-0.041440</td>\n",
              "      <td>2.014376</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1523</th>\n",
              "      <td>283</td>\n",
              "      <td>-1.258657</td>\n",
              "      <td>1.445112</td>\n",
              "      <td>-1.075763</td>\n",
              "      <td>2.930605</td>\n",
              "      <td>-0.347137</td>\n",
              "      <td>-1.022391</td>\n",
              "      <td>-1.798167</td>\n",
              "      <td>0.998816</td>\n",
              "      <td>-2.014007</td>\n",
              "      <td>...</td>\n",
              "      <td>0.293833</td>\n",
              "      <td>-0.216540</td>\n",
              "      <td>-0.294882</td>\n",
              "      <td>0.121743</td>\n",
              "      <td>0.081397</td>\n",
              "      <td>0.162221</td>\n",
              "      <td>0.179926</td>\n",
              "      <td>-0.095770</td>\n",
              "      <td>0.808800</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1524</th>\n",
              "      <td>356</td>\n",
              "      <td>-1.696256</td>\n",
              "      <td>1.675411</td>\n",
              "      <td>-1.279630</td>\n",
              "      <td>3.427237</td>\n",
              "      <td>-0.496162</td>\n",
              "      <td>-1.365022</td>\n",
              "      <td>-2.084248</td>\n",
              "      <td>1.116322</td>\n",
              "      <td>-2.285682</td>\n",
              "      <td>...</td>\n",
              "      <td>0.378256</td>\n",
              "      <td>-0.172784</td>\n",
              "      <td>-0.362762</td>\n",
              "      <td>0.323519</td>\n",
              "      <td>0.074121</td>\n",
              "      <td>0.163484</td>\n",
              "      <td>0.212018</td>\n",
              "      <td>-0.113201</td>\n",
              "      <td>0.464507</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1525</th>\n",
              "      <td>420</td>\n",
              "      <td>-0.728593</td>\n",
              "      <td>0.428636</td>\n",
              "      <td>1.484341</td>\n",
              "      <td>0.169187</td>\n",
              "      <td>0.937816</td>\n",
              "      <td>-0.671453</td>\n",
              "      <td>0.762955</td>\n",
              "      <td>-0.097615</td>\n",
              "      <td>-0.138320</td>\n",
              "      <td>...</td>\n",
              "      <td>0.027491</td>\n",
              "      <td>0.149260</td>\n",
              "      <td>-0.176506</td>\n",
              "      <td>0.036949</td>\n",
              "      <td>0.036538</td>\n",
              "      <td>-0.348434</td>\n",
              "      <td>-0.037484</td>\n",
              "      <td>-0.054870</td>\n",
              "      <td>0.998008</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1526 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Time        V1        V2        V3        V4        V5        V6  \\\n",
              "0        0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
              "1        0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
              "2        1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
              "3        1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
              "4        2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
              "...    ...       ...       ...       ...       ...       ...       ...   \n",
              "1521   496 -1.805938 -2.327118  2.326886  1.097871  2.315570  0.553011   \n",
              "1522   193  0.344351  0.318939  0.795990  0.342021  0.422364 -0.409636   \n",
              "1523   283 -1.258657  1.445112 -1.075763  2.930605 -0.347137 -1.022391   \n",
              "1524   356 -1.696256  1.675411 -1.279630  3.427237 -0.496162 -1.365022   \n",
              "1525   420 -0.728593  0.428636  1.484341  0.169187  0.937816 -0.671453   \n",
              "\n",
              "            V7        V8        V9  ...       V21       V22       V23  \\\n",
              "0     0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474   \n",
              "1    -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288   \n",
              "2     0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412   \n",
              "3     0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321   \n",
              "4     0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "1521 -1.986337  0.745473  0.884782  ...  0.382932  1.083578  0.285854   \n",
              "1522  0.304112 -0.011521 -0.210127  ... -0.108989 -0.270857 -0.042334   \n",
              "1523 -1.798167  0.998816 -2.014007  ...  0.293833 -0.216540 -0.294882   \n",
              "1524 -2.084248  1.116322 -2.285682  ...  0.378256 -0.172784 -0.362762   \n",
              "1525  0.762955 -0.097615 -0.138320  ...  0.027491  0.149260 -0.176506   \n",
              "\n",
              "           V24       V25       V26       V27       V28      Amount  Class  \n",
              "0     0.066928  0.128539 -0.189115  0.133558 -0.021053  149.620000      0  \n",
              "1    -0.339846  0.167170  0.125895 -0.008983  0.014724    2.690000      1  \n",
              "2    -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.660000      0  \n",
              "3    -1.175575  0.647376 -0.221929  0.062723  0.061458  123.500000      0  \n",
              "4     0.141267 -0.206010  0.502292  0.219422  0.215153   69.990000      0  \n",
              "...        ...       ...       ...       ...       ...         ...    ...  \n",
              "1521 -0.825569 -0.195759  0.816201 -0.117572 -0.159734    1.572550      1  \n",
              "1522 -0.049916  0.256699 -0.105876 -0.047148 -0.041440    2.014376      1  \n",
              "1523  0.121743  0.081397  0.162221  0.179926 -0.095770    0.808800      1  \n",
              "1524  0.323519  0.074121  0.163484  0.212018 -0.113201    0.464507      1  \n",
              "1525  0.036949  0.036538 -0.348434 -0.037484 -0.054870    0.998008      1  \n",
              "\n",
              "[1526 rows x 31 columns]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_features"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using Simple Random Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "DEqna4hojALt"
      },
      "outputs": [],
      "source": [
        "#creating a random subset of quantity 1100\n",
        "sample_df=x_features.sample(1100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "pOopwoqmo4dP"
      },
      "outputs": [],
      "source": [
        "x=sample_df.iloc[:, sample_df.columns!= 'Class']\n",
        "y=sample_df.iloc[:,sample_df.columns=='Class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "9A20j0t_fFCM"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.30, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzfIxfYwfyuf",
        "outputId": "b8e00d35-5504-40da-faf3-eb86ecb0c95f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Armaan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "GaussianNB()"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Applying Naive Bayes Classifier\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "NB_classifier = GaussianNB()\n",
        "NB_classifier.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbpy7MIDf7pr",
        "outputId": "aa6ade66-fc3d-4b5e-db91-96533f03435e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 0 0 0 0 0 0 1 1\n",
            " 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1\n",
            " 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 0\n",
            " 1 0 1 0 1 1 1 1 1 0 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 1 0 1 1 1\n",
            " 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1 1 0 1 1 1 0 1 0 0 0 1 1 1\n",
            " 0 0 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 1 1\n",
            " 0 0 1 0 0 1 1 1 1 1 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 0 0\n",
            " 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0\n",
            " 0 0 0 0 1 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 1 1 1 1 0 1 0 0 1 0 1]\n"
          ]
        }
      ],
      "source": [
        "y_pred  =  NB_classifier.predict(x_test)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa5XEaj8gCem",
        "outputId": "89303900-c253-4068-9e04-40fdcef6491c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8515151515151516\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "score=accuracy_score(y_pred,y_test)\n",
        "#score=accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Applying SVM (Support Vector Machine)\n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "svm = SVC(kernel='linear', C=1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Armaan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, kernel=&#x27;linear&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, kernel=&#x27;linear&#x27;, random_state=42)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "SVC(C=1, kernel='linear', random_state=42)"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "svm.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0\n",
            " 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 1\n",
            " 0 0 0 1 1 1 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0\n",
            " 1 0 1 0 1 1 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 0 0 1\n",
            " 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 1\n",
            " 1 0 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 0 1\n",
            " 1 1 1 0 0 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 0 1 1 0 1 0 0\n",
            " 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 0 1 1 0 0\n",
            " 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1]\n"
          ]
        }
      ],
      "source": [
        "y_pred = svm.predict(x_test)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9242424242424242\n"
          ]
        }
      ],
      "source": [
        "#score2 = accuracy_score(y_test, y_pred)\n",
        "\n",
        "score2=accuracy_score(y_pred,y_test)\n",
        "print(score2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "3pyYbYRWgwjL"
      },
      "outputs": [],
      "source": [
        "# Applying Random Forest\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9Vvro2jn3Le",
        "outputId": "fcaf13b0-5909-4d3c-bc2b-79e9615b3d4c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Armaan\\AppData\\Local\\Temp\\ipykernel_8308\\3758756570.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  rf.fit(x_train, y_train)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier()"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfC4TGB2oB_b",
        "outputId": "17295848-846c-45f4-af93-a5a73fc100c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 0 0 1 0\n",
            " 0 1 1 0 1 1 1 0 1 0 1 1 0 0 1 0 1 1 0 0 0 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 1\n",
            " 0 0 0 1 1 1 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 1 1 0\n",
            " 1 0 1 0 1 1 0 1 0 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1\n",
            " 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 1\n",
            " 0 0 1 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 0 1\n",
            " 0 1 1 0 0 0 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0\n",
            " 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0\n",
            " 0 0 1 0 0 0 0 0 1 0 1 1 0 1 0 1 0 0 1 0 1 0 0 1 1 1 0 0 0 0 0 1 0 1]\n"
          ]
        }
      ],
      "source": [
        "y_pred3  =  rf.predict(x_test)\n",
        "print(y_pred3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8kNLxbNoGu8",
        "outputId": "7dbca602-08fb-49b5-8b22-d74efb2fcece"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.996969696969697\n"
          ]
        }
      ],
      "source": [
        "score3=accuracy_score(y_pred3,y_test)\n",
        "print(score3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ5SaPkHp3iO",
        "outputId": "d73db501-1cfc-4985-ee2d-2218175c440b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Armaan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\Armaan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# Applying Logistic Regression\n",
        "from sklearn import linear_model\n",
        "logr = linear_model.LogisticRegression()\n",
        "logr.fit(x_train, y_train)\n",
        "logr_pred = logr.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4o3BMi5p8BA",
        "outputId": "ba6d86da-f0d5-4a48-d624-fec357cd3e36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9030303030303031\n"
          ]
        }
      ],
      "source": [
        "score4=accuracy_score(logr_pred,y_test)\n",
        "print(score4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "WfftpjL9qG7d"
      },
      "outputs": [],
      "source": [
        "# Applying Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "DT_clf = DecisionTreeClassifier()\n",
        "DT_clf = DT_clf.fit(x_train,y_train)\n",
        "y_pred5 = DT_clf.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Wp6LwtAsAW7",
        "outputId": "3d34dba7-8c2f-4a23-9d5a-e85bca5dfa15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.996969696969697\n"
          ]
        }
      ],
      "source": [
        "score5=accuracy_score(y_pred3,y_test)\n",
        "print(score5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGV27yZLv3y6",
        "outputId": "6cce28e9-c097-43d3-9c52-4fcf206febed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.8515151515151516,\n",
              " 0.9242424242424242,\n",
              " 0.996969696969697,\n",
              " 0.9030303030303031,\n",
              " 0.996969696969697]"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "simple_sampling=[score,score2,score3,score4,score5]\n",
        "simple_sampling"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_c-hj2xGMY1e"
      },
      "source": [
        "By Doing Startified Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "7s0CAaDEwXAc"
      },
      "outputs": [],
      "source": [
        "stratified=x_features.groupby('Class', group_keys=False).apply(lambda x: x.sample(392,replace=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "UN-qYuL_xPR5"
      },
      "outputs": [],
      "source": [
        "x=stratified.iloc[:, stratified.columns!= 'Class']\n",
        "y=stratified.iloc[:,stratified.columns=='Class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "fuNOLnhXxTJm"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0245YS0xkGj",
        "outputId": "aff17025-4f2d-4225-d061-dee5cb243ace"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8662420382165605\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Armaan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "# Applying Naive Bayes Classifier\n",
        "NB_classifier = GaussianNB()\n",
        "NB_classifier.fit(x_train, y_train)\n",
        "y_pred6  =  NB_classifier.predict(x_test)\n",
        "score6=accuracy_score(y_pred6,y_test)\n",
        "print(score6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Armaan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 1 1\n",
            " 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 0 1 0 1 1\n",
            " 0 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 0 1\n",
            " 0 1 0 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 1 0 0 0 1 0 0 1\n",
            " 0 1 0 1 0 0 1 0 1]\n",
            "0.9490445859872612\n"
          ]
        }
      ],
      "source": [
        "# Applying SVM (Support Vector Machine)\n",
        "from sklearn.svm import SVC\n",
        "svm = SVC(kernel='linear', C=1, random_state=42)\n",
        "svm.fit(x_train, y_train)\n",
        "y_pred7 = svm.predict(x_test)\n",
        "print(y_pred7)\n",
        "score7=accuracy_score(y_pred7,y_test)\n",
        "print(score7)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccSBpWz8yCv6",
        "outputId": "d1c4c1e6-d03f-4c2e-80b8-a1a808b27266"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Armaan\\AppData\\Local\\Temp\\ipykernel_8308\\2271657564.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  rf.fit(x_train, y_train)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9936305732484076\n"
          ]
        }
      ],
      "source": [
        "# Applying Random forest\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(x_train, y_train)\n",
        "y_pred8  =  rf.predict(x_test)\n",
        "score8=accuracy_score(y_pred8,y_test)\n",
        "print(score8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV4nH2GBy5SH",
        "outputId": "407be019-6149-4184-fa24-67c53241efea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9617834394904459\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Armaan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\Armaan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# Applying Logistic regression\n",
        "logr = linear_model.LogisticRegression()\n",
        "logr.fit(x_train, y_train)\n",
        "pred9 = logr.predict(x_test)\n",
        "score9=accuracy_score(pred9,y_test)\n",
        "print(score9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8CbyrrozNyF",
        "outputId": "112d780b-baaf-4543-b839-2390e008569e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9745222929936306\n"
          ]
        }
      ],
      "source": [
        "# Applying Decision Tree Classifier\n",
        "DT_clf = DecisionTreeClassifier()\n",
        "DT_clf = DT_clf.fit(x_train,y_train)\n",
        "y_pred10 = DT_clf.predict(x_test)\n",
        "score10=accuracy_score(y_pred10,y_test)\n",
        "print(score10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X76zwEDCzzBK",
        "outputId": "f229c76a-53d2-4931-cefb-90f586a1ba56"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.8662420382165605,\n",
              " 0.9490445859872612,\n",
              " 0.9936305732484076,\n",
              " 0.9617834394904459,\n",
              " 0.9745222929936306]"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stratified_sampling=[score6,score7,score8,score9,score10]\n",
        "stratified_sampling"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "O9MRTxWzMk9Y"
      },
      "source": [
        "By Doing Systematic Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "dAjsMZKbOgRh"
      },
      "outputs": [],
      "source": [
        "def systematic_sampling(df, step):\n",
        "    indexes = np.arange(0, len(df), step=step)\n",
        "    systematic_sample = df.iloc[indexes]\n",
        "    return systematic_sample\n",
        "data = systematic_sampling(x_features, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "tZwgDX5rPE88"
      },
      "outputs": [],
      "source": [
        "x = data.iloc[:,data.columns!='Class']\n",
        "y = data.iloc[:,data.columns=='Class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "IqL-KEEuPU_o"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwDhlgggPgii",
        "outputId": "0ef7efbd-09f4-4dec-a759-53f1dad4ab2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.869281045751634\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Armaan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "# Applying Naive Bayes\n",
        "NB_classifier = GaussianNB()\n",
        "NB_classifier.fit(x_train, y_train)\n",
        "y_pred11  =  NB_classifier.predict(x_test)\n",
        "score11=accuracy_score(y_pred11,y_test)\n",
        "print(score11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Armaan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8562091503267973\n"
          ]
        }
      ],
      "source": [
        "# Applying SVM (Support Vector Machine)\n",
        "from sklearn.svm import SVC\n",
        "svm = SVC(kernel='linear', C=1, random_state=42)\n",
        "svm.fit(x_train, y_train)\n",
        "y_pred12 = svm.predict(x_test)\n",
        "score12=accuracy_score(y_pred12,y_test)\n",
        "print(score12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0vQ26ebPriz",
        "outputId": "a6d32eb8-a2b4-4e2e-8a38-6017b23c3b28"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Armaan\\AppData\\Local\\Temp\\ipykernel_8308\\983430039.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  rf.fit(x_train, y_train)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9934640522875817\n"
          ]
        }
      ],
      "source": [
        "# Applying Random forest\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(x_train, y_train)\n",
        "y_pred13  =  rf.predict(x_test)\n",
        "score13=accuracy_score(y_pred13,y_test)\n",
        "print(score13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8HsdNE4P2A6",
        "outputId": "9f9dcab0-a4c2-47fb-bfc1-89b3e0fc79d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8496732026143791\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Armaan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\Armaan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# Logistic regression\n",
        "logr = linear_model.LogisticRegression()\n",
        "logr.fit(x_train, y_train)\n",
        "pred14 = logr.predict(x_test)\n",
        "score14=accuracy_score(pred14,y_test)\n",
        "print(score14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkyXTf_VQNKs",
        "outputId": "bc1ea989-8436-4e01-9068-cbbab1795945"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9673202614379085\n"
          ]
        }
      ],
      "source": [
        "# Decision Tree Classifier\n",
        "DT_clf = DecisionTreeClassifier()\n",
        "DT_clf = DT_clf.fit(x_train,y_train)\n",
        "y_pred15 = DT_clf.predict(x_test)\n",
        "score15=accuracy_score(y_pred15,y_test)\n",
        "print(score15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_AW9omLRAOF",
        "outputId": "b1503d77-a5da-4641-c19c-1d28ba409d9d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.869281045751634,\n",
              " 0.8562091503267973,\n",
              " 0.9934640522875817,\n",
              " 0.8496732026143791,\n",
              " 0.9673202614379085]"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "systematic_sampling=[score11,score12,score13,score14,score15]\n",
        "systematic_sampling"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WSdS8EsCUTl9"
      },
      "source": [
        "By Doing Cluster Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "hTiM_MsiRK_6",
        "outputId": "6a124087-de60-440f-a275-3304ea034b42"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "      <th>cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>791</th>\n",
              "      <td>409</td>\n",
              "      <td>-2.237754</td>\n",
              "      <td>1.918880</td>\n",
              "      <td>-1.569865</td>\n",
              "      <td>3.928912</td>\n",
              "      <td>-0.518758</td>\n",
              "      <td>-1.419055</td>\n",
              "      <td>-2.482488</td>\n",
              "      <td>1.358239</td>\n",
              "      <td>-2.712001</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.051438</td>\n",
              "      <td>-0.452843</td>\n",
              "      <td>0.320677</td>\n",
              "      <td>0.048203</td>\n",
              "      <td>0.176099</td>\n",
              "      <td>0.255234</td>\n",
              "      <td>-0.139641</td>\n",
              "      <td>0.026911</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>89</td>\n",
              "      <td>0.270725</td>\n",
              "      <td>-1.615317</td>\n",
              "      <td>1.054982</td>\n",
              "      <td>1.661510</td>\n",
              "      <td>-1.737687</td>\n",
              "      <td>0.065894</td>\n",
              "      <td>-0.313977</td>\n",
              "      <td>0.089081</td>\n",
              "      <td>1.069842</td>\n",
              "      <td>...</td>\n",
              "      <td>0.496083</td>\n",
              "      <td>-0.482194</td>\n",
              "      <td>0.418871</td>\n",
              "      <td>0.235961</td>\n",
              "      <td>-0.265185</td>\n",
              "      <td>-0.001063</td>\n",
              "      <td>0.120126</td>\n",
              "      <td>459.390000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048</th>\n",
              "      <td>518</td>\n",
              "      <td>-2.028025</td>\n",
              "      <td>-2.103660</td>\n",
              "      <td>2.107964</td>\n",
              "      <td>1.391831</td>\n",
              "      <td>2.199101</td>\n",
              "      <td>0.416228</td>\n",
              "      <td>-2.147819</td>\n",
              "      <td>0.841499</td>\n",
              "      <td>0.630292</td>\n",
              "      <td>...</td>\n",
              "      <td>1.086991</td>\n",
              "      <td>0.230612</td>\n",
              "      <td>-0.753384</td>\n",
              "      <td>-0.196077</td>\n",
              "      <td>0.800831</td>\n",
              "      <td>-0.090636</td>\n",
              "      <td>-0.168612</td>\n",
              "      <td>1.367850</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>413</td>\n",
              "      <td>-1.581222</td>\n",
              "      <td>0.391512</td>\n",
              "      <td>1.916333</td>\n",
              "      <td>-0.087840</td>\n",
              "      <td>-0.421410</td>\n",
              "      <td>0.270447</td>\n",
              "      <td>-0.135966</td>\n",
              "      <td>0.231828</td>\n",
              "      <td>0.377201</td>\n",
              "      <td>...</td>\n",
              "      <td>0.621812</td>\n",
              "      <td>0.213053</td>\n",
              "      <td>0.018859</td>\n",
              "      <td>-0.305393</td>\n",
              "      <td>0.300156</td>\n",
              "      <td>-0.287681</td>\n",
              "      <td>0.185402</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>870</th>\n",
              "      <td>56</td>\n",
              "      <td>1.221837</td>\n",
              "      <td>0.306154</td>\n",
              "      <td>0.231145</td>\n",
              "      <td>0.564621</td>\n",
              "      <td>-0.145134</td>\n",
              "      <td>-0.552057</td>\n",
              "      <td>-0.000076</td>\n",
              "      <td>-0.051799</td>\n",
              "      <td>-0.117269</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.730914</td>\n",
              "      <td>0.114028</td>\n",
              "      <td>-0.016885</td>\n",
              "      <td>0.190360</td>\n",
              "      <td>0.111065</td>\n",
              "      <td>-0.015816</td>\n",
              "      <td>0.022411</td>\n",
              "      <td>2.690000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>184</td>\n",
              "      <td>1.199278</td>\n",
              "      <td>0.365738</td>\n",
              "      <td>0.428155</td>\n",
              "      <td>0.617733</td>\n",
              "      <td>-0.342610</td>\n",
              "      <td>-0.845869</td>\n",
              "      <td>0.041919</td>\n",
              "      <td>-0.114617</td>\n",
              "      <td>-0.360600</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.615517</td>\n",
              "      <td>0.132391</td>\n",
              "      <td>0.517045</td>\n",
              "      <td>0.185487</td>\n",
              "      <td>0.061686</td>\n",
              "      <td>-0.021504</td>\n",
              "      <td>0.024434</td>\n",
              "      <td>1.980000</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>594</th>\n",
              "      <td>446</td>\n",
              "      <td>-1.146103</td>\n",
              "      <td>1.350274</td>\n",
              "      <td>0.907209</td>\n",
              "      <td>-0.040682</td>\n",
              "      <td>-0.242920</td>\n",
              "      <td>-1.099859</td>\n",
              "      <td>0.579042</td>\n",
              "      <td>0.045619</td>\n",
              "      <td>0.460784</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.895759</td>\n",
              "      <td>0.099686</td>\n",
              "      <td>0.275643</td>\n",
              "      <td>-0.045217</td>\n",
              "      <td>0.095849</td>\n",
              "      <td>0.563119</td>\n",
              "      <td>0.307945</td>\n",
              "      <td>17.990000</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1379</th>\n",
              "      <td>536</td>\n",
              "      <td>-1.462010</td>\n",
              "      <td>-2.022722</td>\n",
              "      <td>2.110088</td>\n",
              "      <td>1.065770</td>\n",
              "      <td>1.995929</td>\n",
              "      <td>0.319595</td>\n",
              "      <td>-1.745811</td>\n",
              "      <td>0.623282</td>\n",
              "      <td>0.802718</td>\n",
              "      <td>...</td>\n",
              "      <td>0.862164</td>\n",
              "      <td>0.269709</td>\n",
              "      <td>-0.658720</td>\n",
              "      <td>-0.146522</td>\n",
              "      <td>0.734304</td>\n",
              "      <td>-0.107691</td>\n",
              "      <td>-0.137671</td>\n",
              "      <td>1.465289</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>71</td>\n",
              "      <td>1.331897</td>\n",
              "      <td>-0.579962</td>\n",
              "      <td>0.422606</td>\n",
              "      <td>-0.897752</td>\n",
              "      <td>-0.746254</td>\n",
              "      <td>-0.056273</td>\n",
              "      <td>-0.750317</td>\n",
              "      <td>0.128484</td>\n",
              "      <td>-0.964682</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.255174</td>\n",
              "      <td>0.109333</td>\n",
              "      <td>-0.328448</td>\n",
              "      <td>0.162254</td>\n",
              "      <td>-0.447276</td>\n",
              "      <td>0.020071</td>\n",
              "      <td>0.006231</td>\n",
              "      <td>14.480000</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1136</th>\n",
              "      <td>410</td>\n",
              "      <td>0.785863</td>\n",
              "      <td>0.438968</td>\n",
              "      <td>0.364685</td>\n",
              "      <td>0.461260</td>\n",
              "      <td>0.112676</td>\n",
              "      <td>-0.541939</td>\n",
              "      <td>0.174778</td>\n",
              "      <td>-0.070923</td>\n",
              "      <td>-0.040334</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.645847</td>\n",
              "      <td>0.136966</td>\n",
              "      <td>-0.337068</td>\n",
              "      <td>-0.420467</td>\n",
              "      <td>0.086829</td>\n",
              "      <td>0.078993</td>\n",
              "      <td>0.110326</td>\n",
              "      <td>1.170464</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>545 rows × 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Time        V1        V2        V3        V4        V5        V6  \\\n",
              "791    409 -2.237754  1.918880 -1.569865  3.928912 -0.518758 -1.419055   \n",
              "142     89  0.270725 -1.615317  1.054982  1.661510 -1.737687  0.065894   \n",
              "1048   518 -2.028025 -2.103660  2.107964  1.391831  2.199101  0.416228   \n",
              "554    413 -1.581222  0.391512  1.916333 -0.087840 -0.421410  0.270447   \n",
              "870     56  1.221837  0.306154  0.231145  0.564621 -0.145134 -0.552057   \n",
              "...    ...       ...       ...       ...       ...       ...       ...   \n",
              "261    184  1.199278  0.365738  0.428155  0.617733 -0.342610 -0.845869   \n",
              "594    446 -1.146103  1.350274  0.907209 -0.040682 -0.242920 -1.099859   \n",
              "1379   536 -1.462010 -2.022722  2.110088  1.065770  1.995929  0.319595   \n",
              "107     71  1.331897 -0.579962  0.422606 -0.897752 -0.746254 -0.056273   \n",
              "1136   410  0.785863  0.438968  0.364685  0.461260  0.112676 -0.541939   \n",
              "\n",
              "            V7        V8        V9  ...       V22       V23       V24  \\\n",
              "791  -2.482488  1.358239 -2.712001  ... -0.051438 -0.452843  0.320677   \n",
              "142  -0.313977  0.089081  1.069842  ...  0.496083 -0.482194  0.418871   \n",
              "1048 -2.147819  0.841499  0.630292  ...  1.086991  0.230612 -0.753384   \n",
              "554  -0.135966  0.231828  0.377201  ...  0.621812  0.213053  0.018859   \n",
              "870  -0.000076 -0.051799 -0.117269  ... -0.730914  0.114028 -0.016885   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "261   0.041919 -0.114617 -0.360600  ... -0.615517  0.132391  0.517045   \n",
              "594   0.579042  0.045619  0.460784  ... -0.895759  0.099686  0.275643   \n",
              "1379 -1.745811  0.623282  0.802718  ...  0.862164  0.269709 -0.658720   \n",
              "107  -0.750317  0.128484 -0.964682  ... -0.255174  0.109333 -0.328448   \n",
              "1136  0.174778 -0.070923 -0.040334  ... -0.645847  0.136966 -0.337068   \n",
              "\n",
              "           V25       V26       V27       V28      Amount  Class  cluster  \n",
              "791   0.048203  0.176099  0.255234 -0.139641    0.026911      1        0  \n",
              "142   0.235961 -0.265185 -0.001063  0.120126  459.390000      0        0  \n",
              "1048 -0.196077  0.800831 -0.090636 -0.168612    1.367850      1        0  \n",
              "554  -0.305393  0.300156 -0.287681  0.185402   30.000000      0        0  \n",
              "870   0.190360  0.111065 -0.015816  0.022411    2.690000      1        0  \n",
              "...        ...       ...       ...       ...         ...    ...      ...  \n",
              "261   0.185487  0.061686 -0.021504  0.024434    1.980000      0       12  \n",
              "594  -0.045217  0.095849  0.563119  0.307945   17.990000      0       12  \n",
              "1379 -0.146522  0.734304 -0.107691 -0.137671    1.465289      1       12  \n",
              "107   0.162254 -0.447276  0.020071  0.006231   14.480000      0       12  \n",
              "1136 -0.420467  0.086829  0.078993  0.110326    1.170464      1       12  \n",
              "\n",
              "[545 rows x 32 columns]"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_clustered_Sample(df, n_per_cluster, num_select_clusters):\n",
        "    N = len(df)\n",
        "    K = int(N/n_per_cluster)\n",
        "    data = None\n",
        "    for k in range(K):\n",
        "        sample_k = df.sample(n_per_cluster)\n",
        "        sample_k[\"cluster\"] = np.repeat(k,len(sample_k))\n",
        "        df = df.drop(index = sample_k.index)\n",
        "        data = pd.concat([data,sample_k],axis = 0)\n",
        "    random_chosen_clusters = np.random.randint(0,K,size = num_select_clusters)\n",
        "    samples = data[data.cluster.isin(random_chosen_clusters)]\n",
        "    return(samples)\n",
        "cluster_data = get_clustered_Sample(df = x_features, n_per_cluster = 109, num_select_clusters = 7)\n",
        "cluster_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "oq1056_VU6dC"
      },
      "outputs": [],
      "source": [
        "x = cluster_data.iloc[:,cluster_data.columns!='Class']\n",
        "y = cluster_data.iloc[:,cluster_data.columns=='Class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "D3etMeK_Xdxo"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehtfo1R2XrMk",
        "outputId": "4a1fdeee-2e36-4c41-d6f5-fae3e07180df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7889908256880734\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Armaan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "# Naive Bayes\n",
        "NB_classifier = GaussianNB()\n",
        "NB_classifier.fit(x_train, y_train)\n",
        "y_pred16  =  NB_classifier.predict(x_test)\n",
        "score16=accuracy_score(y_pred16,y_test)\n",
        "print(score16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Armaan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.908256880733945\n"
          ]
        }
      ],
      "source": [
        "# Applying SVM (Support Vector Machine)\n",
        "from sklearn.svm import SVC\n",
        "svm = SVC(kernel='linear', C=1, random_state=42)\n",
        "svm.fit(x_train, y_train)\n",
        "y_pred17 = svm.predict(x_test)\n",
        "score17=accuracy_score(y_pred17,y_test)\n",
        "print(score17)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmPVFO7iX0Lu",
        "outputId": "0138fc7e-869e-4d46-99e3-04e35b8bf597"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Armaan\\AppData\\Local\\Temp\\ipykernel_8308\\3386496693.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  rf.fit(x_train, y_train)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9908256880733946\n"
          ]
        }
      ],
      "source": [
        "# Random Forest\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(x_train, y_train)\n",
        "y_pred18  =  rf.predict(x_test)\n",
        "score18=accuracy_score(y_pred18,y_test)\n",
        "print(score18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YF9l1UiXYXPr",
        "outputId": "0db6284c-3371-423e-97db-326ed8047f58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8899082568807339\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Armaan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\Armaan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression\n",
        "logr = linear_model.LogisticRegression()\n",
        "logr.fit(x_train, y_train)\n",
        "pred19 = logr.predict(x_test)\n",
        "score19=accuracy_score(pred19,y_test)\n",
        "print(score19)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0DW6KfwYg-L",
        "outputId": "29eb1bfc-6dce-479c-eeb0-ecc2684714a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.944954128440367\n"
          ]
        }
      ],
      "source": [
        "# Decision Tree Classifier\n",
        "DT_clf = DecisionTreeClassifier()\n",
        "DT_clf = DT_clf.fit(x_train,y_train)\n",
        "y_pred20 = DT_clf.predict(x_test)\n",
        "score20=accuracy_score(y_pred20,y_test)\n",
        "print(score20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OeaxVttY1s2",
        "outputId": "0d1a9df2-53ba-407a-ec76-e5b6827e0367"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.7889908256880734,\n",
              " 0.908256880733945,\n",
              " 0.9908256880733946,\n",
              " 0.8899082568807339,\n",
              " 0.944954128440367]"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cluster_sampling=[score16,score17,score18,score19,score20]\n",
        "cluster_sampling"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-jPe1kwwBJu"
      },
      "source": [
        "Finally comibining all the calculated accuracies of different sampling techniques in one Data Frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "aVgxn_1x7yy9"
      },
      "outputs": [],
      "source": [
        "df2=pd.DataFrame\n",
        "model=['Naive Bayes','Support Vector Machine','Random Forest','Logistic Regression','Decision Tree classifier']\n",
        "resultanttable= {\n",
        "    'Models': model,\n",
        "    'Simple random Sampling':simple_sampling,\n",
        "    'Stratified Sampling' :stratified_sampling,\n",
        "    'Systematic Sampling': systematic_sampling,\n",
        "    'Cluster Sampling':cluster_sampling\n",
        "          }\n",
        "df2 = pd.DataFrame(resultanttable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Models</th>\n",
              "      <th>Simple random Sampling</th>\n",
              "      <th>Stratified Sampling</th>\n",
              "      <th>Systematic Sampling</th>\n",
              "      <th>Cluster Sampling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.851515</td>\n",
              "      <td>0.866242</td>\n",
              "      <td>0.869281</td>\n",
              "      <td>0.788991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Support Vector Machine</td>\n",
              "      <td>0.924242</td>\n",
              "      <td>0.949045</td>\n",
              "      <td>0.856209</td>\n",
              "      <td>0.908257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.996970</td>\n",
              "      <td>0.993631</td>\n",
              "      <td>0.993464</td>\n",
              "      <td>0.990826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.903030</td>\n",
              "      <td>0.961783</td>\n",
              "      <td>0.849673</td>\n",
              "      <td>0.889908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Decision Tree classifier</td>\n",
              "      <td>0.996970</td>\n",
              "      <td>0.974522</td>\n",
              "      <td>0.967320</td>\n",
              "      <td>0.944954</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Models  Simple random Sampling  Stratified Sampling  \\\n",
              "0               Naive Bayes                0.851515             0.866242   \n",
              "1    Support Vector Machine                0.924242             0.949045   \n",
              "2             Random Forest                0.996970             0.993631   \n",
              "3       Logistic Regression                0.903030             0.961783   \n",
              "4  Decision Tree classifier                0.996970             0.974522   \n",
              "\n",
              "   Systematic Sampling  Cluster Sampling  \n",
              "0             0.869281          0.788991  \n",
              "1             0.856209          0.908257  \n",
              "2             0.993464          0.990826  \n",
              "3             0.849673          0.889908  \n",
              "4             0.967320          0.944954  "
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "d8_BwPwyJjCc"
      },
      "source": [
        "Following Conclusions can be made from the above table:\n",
        "1) Naive Bayes works best with Systematic Sampling\n",
        "2) Support Vector Machine works best with Stratified Sampling\n",
        "3) Random Forest works best with Simple random Sampling\n",
        "4) Logistic Regression works best with Stratified Sampling\n",
        "5) Decision Tree classifier works best with Simple random Sampling"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "84a8a41a5778bff538cb8d591963c822cdb39704d387ac1907c023fd615b6fc7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
